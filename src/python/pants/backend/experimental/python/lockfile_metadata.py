# Copyright 2021 Pants project contributors (see CONTRIBUTORS.md).
# Licensed under the Apache License, Version 2.0 (see LICENSE).

from __future__ import annotations

import hashlib
import json
from dataclasses import dataclass
from typing import Any, Callable, Iterable, TypeVar

from pants.backend.python.util_rules.interpreter_constraints import InterpreterConstraints
from pants.util.ordered_set import FrozenOrderedSet

BEGIN_LOCKFILE_HEADER = b"# --- BEGIN PANTS LOCKFILE METADATA: DO NOT EDIT OR REMOVE ---"
END_LOCKFILE_HEADER = b"# --- END PANTS LOCKFILE METADATA ---"


@dataclass
class LockfileMetadata:
    requirements_invalidation_digest: str | None
    valid_for_interpreter_constraints: InterpreterConstraints | None

    @staticmethod
    def from_json_bytes(json_literal: str | bytes) -> LockfileMetadata:
        """Reads a `string`/`bytes` that has JSON-encoded a `LockfileMetadata` object, returning
        that deserialized object."""
        try:
            metadata = json.loads(json_literal)
        except json.decoder.JSONDecodeError:
            # If this block is invalid, this should trigger error/warning behavior
            metadata = {}

        T = TypeVar("T")

        def coerce(t: Callable[[Any], T], key: str) -> T | None:
            """Gets a value from `metadata`, coercing it to type `t` if not `None`."""
            v = metadata.get(key, None)
            try:
                return t(v) if v is not None else None
            except Exception:
                # TODO: this should trigger error/warning behavior
                return None

        return LockfileMetadata(
            requirements_invalidation_digest=coerce(str, "requirements_invalidation_digest"),
            valid_for_interpreter_constraints=coerce(
                InterpreterConstraints, "valid_for_interpreter_constraints"
            ),
        )

    def to_json_literal(self) -> str:
        """Produces a JSON-encoded dictionary that represents the contents of this metadata."""
        constraints = self.valid_for_interpreter_constraints
        metadata = {
            "requirements_invalidation_digest": self.requirements_invalidation_digest,
            "valid_for_interpreter_constraints": [str(i) for i in constraints]
            if constraints
            else None,
        }
        return json.dumps(
            metadata,
            ensure_ascii=True,
            indent=2,
        )

    def is_valid_for(
        self,
        expected_invalidation_digest: str | None,
        user_interpreter_constraints: InterpreterConstraints,
        interpreter_universe: Iterable[str],
    ) -> bool:
        """Returns True if this `LockfileMetadata` represents a lockfile that can be used in the
        current execution context.

        A lockfile can be used in the current execution context if `expected_invalidation_digest ==
        requirements_invalidation_digest`, and if `user_interpreter_constraints` matches only
        interpreters specified by `valid_for_interpreter_constraints`.
        """

        if expected_invalidation_digest is None:
            return True

        if self.requirements_invalidation_digest != expected_invalidation_digest:
            return False

        if self.valid_for_interpreter_constraints is None:
            # This lockfile matches all interpreter constraints (TODO: check this)
            return True

        return self.valid_for_interpreter_constraints.contains(
            user_interpreter_constraints, interpreter_universe
        )


def calculate_invalidation_digest(
    requirements: FrozenOrderedSet[str],
) -> str:
    """Returns an invalidation digest for the given requirements."""
    m = hashlib.sha256()
    inputs = {
        "requirements": list(requirements),
    }
    m.update(json.dumps(inputs).encode("utf-8"))
    return m.hexdigest()


def lockfile_content_with_header(
    regenerate_command: str,
    invalidation_digest: str,
    interpreter_constraints: InterpreterConstraints,
    content: bytes,
) -> bytes:
    """Returns a version of the lockfile with Pants metadata and usage instructions prepended."""
    regenerate_command = (
        f"# This lockfile was autogenerated by Pants. To regenerate, run:\n#\n"
        f"#    {regenerate_command}"
    )
    return b"%b\n#\n%b\n\n%b" % (
        regenerate_command.encode("utf-8"),
        lockfile_metadata_header(LockfileMetadata(invalidation_digest, interpreter_constraints)),
        content,
    )


def lockfile_metadata_header(metadata: LockfileMetadata) -> bytes:
    """Produces a metadata bytes object for including at the top of a lockfile.

    Currently, this only consists of an invalidation digest for the file, which is used when Pants
    consumes the lockfile during builds.
    """

    metadata_as_comment = "\n".join(f"# {i}" for i in metadata.to_json_literal().splitlines())

    return (
        b"""
%(BEGIN_LOCKFILE_HEADER)b
%(metadata_as_comment)s
%(END_LOCKFILE_HEADER)b
    """
        % {
            b"BEGIN_LOCKFILE_HEADER": BEGIN_LOCKFILE_HEADER,
            b"metadata_as_comment": metadata_as_comment.encode("ascii"),
            b"END_LOCKFILE_HEADER": END_LOCKFILE_HEADER,
        }
    ).strip()


def read_lockfile_metadata(contents: bytes) -> LockfileMetadata:
    """Reads through `contents`, and returns the contents of the lockfile metadata block as a
    `LockfileMetadata` object."""

    def yield_metadata_lines() -> Iterable[bytes]:
        """Splits contents into lines and yields only the lines that are strictly inside the
        metadata header block."""
        in_metadata_block = False
        for line in contents.splitlines():
            if line == BEGIN_LOCKFILE_HEADER:
                in_metadata_block = True
            elif line == END_LOCKFILE_HEADER:
                break
            elif in_metadata_block:
                yield line[2:]

    metadata_lines = b"\n".join(yield_metadata_lines())

    return LockfileMetadata.from_json_bytes(metadata_lines)
