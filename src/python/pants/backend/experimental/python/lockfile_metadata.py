# Copyright 2021 Pants project contributors (see CONTRIBUTORS.md).
# Licensed under the Apache License, Version 2.0 (see LICENSE).

from __future__ import annotations

import hashlib
import json
from dataclasses import dataclass
from typing import Any, Callable, Iterable, TypeVar

from pants.backend.python.util_rules.interpreter_constraints import InterpreterConstraints

BEGIN_LOCKFILE_HEADER = b"# --- BEGIN PANTS LOCKFILE METADATA: DO NOT EDIT OR REMOVE ---"
END_LOCKFILE_HEADER = b"# --- END PANTS LOCKFILE METADATA ---"


@dataclass
class LockfileMetadata:
    requirements_invalidation_digest: str | None
    valid_for_interpreter_constraints: InterpreterConstraints | None

    @classmethod
    def from_lockfile(cls, lockfile: bytes) -> LockfileMetadata:
        """Parse all relevant metadata from the lockfile's header."""
        in_metadata_block = False
        metadata_lines = []
        for line in lockfile.splitlines():
            if line == BEGIN_LOCKFILE_HEADER:
                in_metadata_block = True
            elif line == END_LOCKFILE_HEADER:
                break
            elif in_metadata_block:
                metadata_lines.append(line[2:])

        try:
            metadata = json.loads(b"\n".join(metadata_lines))
        except json.decoder.JSONDecodeError:
            # TODO(#12314): Add a good error.
            raise

        T = TypeVar("T")

        def coerce(t: Callable[[Any], T], key: str) -> T | None:
            """Gets a value from `metadata`, coercing it to type `t` if not `None`."""
            v = metadata.get(key, None)
            try:
                return t(v) if v is not None else None
            except Exception:
                # TODO: this should trigger error/warning behavior
                return None

        return LockfileMetadata(
            requirements_invalidation_digest=coerce(str, "requirements_invalidation_digest"),
            valid_for_interpreter_constraints=coerce(
                InterpreterConstraints, "valid_for_interpreter_constraints"
            ),
        )

    def add_header_to_lockfile(self, lockfile: bytes, *, regenerate_command: str) -> bytes:
        metadata_as_a_comment = "\n".join(f"# {i}" for i in self._to_json().splitlines()).encode(
            "ascii"
        )
        header = b"%b\n%b\n%b" % (BEGIN_LOCKFILE_HEADER, metadata_as_a_comment, END_LOCKFILE_HEADER)

        regenerate_command_bytes = (
            f"# This lockfile was autogenerated by Pants. To regenerate, run:\n#\n"
            f"#    {regenerate_command}"
        ).encode("utf-8")

        return b"%b\n#\n%b\n\n%b" % (regenerate_command_bytes, header, lockfile)

    def _to_json(self) -> str:
        """Produces a JSON-encoded dictionary that represents the contents of this metadata."""
        constraints = self.valid_for_interpreter_constraints
        metadata = {
            "requirements_invalidation_digest": self.requirements_invalidation_digest,
            "valid_for_interpreter_constraints": [str(i) for i in constraints]
            if constraints
            else None,
        }
        return json.dumps(metadata, ensure_ascii=True, indent=2)

    def is_valid_for(
        self,
        expected_invalidation_digest: str | None,
        user_interpreter_constraints: InterpreterConstraints,
        interpreter_universe: Iterable[str],
    ) -> bool:
        """Returns True if this `LockfileMetadata` represents a lockfile that can be used in the
        current execution context.

        A lockfile can be used in the current execution context if `expected_invalidation_digest ==
        requirements_invalidation_digest`, and if `user_interpreter_constraints` matches only
        interpreters specified by `valid_for_interpreter_constraints`.
        """

        if expected_invalidation_digest is None:
            return True

        if self.requirements_invalidation_digest != expected_invalidation_digest:
            return False

        if self.valid_for_interpreter_constraints is None:
            # This lockfile matches all interpreter constraints (TODO: check this)
            return True

        return self.valid_for_interpreter_constraints.contains(
            user_interpreter_constraints, interpreter_universe
        )


def calculate_invalidation_digest(requirements: Iterable[str]) -> str:
    """Returns an invalidation digest for the given requirements."""
    m = hashlib.sha256()
    inputs = {
        "requirements": list(requirements),
    }
    m.update(json.dumps(inputs).encode("utf-8"))
    return m.hexdigest()
