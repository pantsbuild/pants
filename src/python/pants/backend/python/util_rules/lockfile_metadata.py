# Copyright 2021 Pants project contributors (see CONTRIBUTORS.md).
# Licensed under the Apache License, Version 2.0 (see LICENSE).

from __future__ import annotations

import hashlib
import json
from dataclasses import dataclass
from enum import Enum
from typing import Any, Iterable

from pants.backend.python.util_rules.interpreter_constraints import InterpreterConstraints
from pants.util.ordered_set import FrozenOrderedSet

BEGIN_LOCKFILE_HEADER = b"# --- BEGIN PANTS LOCKFILE METADATA: DO NOT EDIT OR REMOVE ---"
END_LOCKFILE_HEADER = b"# --- END PANTS LOCKFILE METADATA ---"


class InvalidLockfileError(Exception):
    pass


@dataclass
class LockfileMetadata:
    requirements_invalidation_digest: str
    valid_for_interpreter_constraints: InterpreterConstraints

    @classmethod
    def from_lockfile(cls, lockfile: bytes) -> LockfileMetadata:
        """Parse all relevant metadata from the lockfile's header."""
        in_metadata_block = False
        metadata_lines = []
        for line in lockfile.splitlines():
            if line == BEGIN_LOCKFILE_HEADER:
                in_metadata_block = True
            elif line == END_LOCKFILE_HEADER:
                break
            elif in_metadata_block:
                metadata_lines.append(line[2:])

        if not metadata_lines:
            # TODO(#12314): Add a good error.
            raise InvalidLockfileError("")

        try:
            metadata = json.loads(b"\n".join(metadata_lines))
        except json.decoder.JSONDecodeError:
            # TODO(#12314): Add a good error.
            raise InvalidLockfileError("")

        def get_or_raise(key: str) -> Any:
            try:
                return metadata[key]
            except KeyError:
                # TODO(#12314): Add a good error about the key not being defined.
                raise InvalidLockfileError("")

        requirements_digest = get_or_raise("requirements_invalidation_digest")
        if not isinstance(requirements_digest, str):
            # TODO(#12314): Add a good error about invalid data type.
            raise InvalidLockfileError("")

        try:
            interpreter_constraints = InterpreterConstraints(
                get_or_raise("valid_for_interpreter_constraints")
            )
        except TypeError:
            # TODO(#12314): Add a good error about invalid data type.
            raise InvalidLockfileError("")

        return LockfileMetadata(requirements_digest, interpreter_constraints)

    def add_header_to_lockfile(self, lockfile: bytes, *, regenerate_command: str) -> bytes:
        metadata_dict = {
            "requirements_invalidation_digest": self.requirements_invalidation_digest,
            "valid_for_interpreter_constraints": [
                str(ic) for ic in self.valid_for_interpreter_constraints
            ],
        }
        metadata_json = json.dumps(metadata_dict, ensure_ascii=True, indent=2).splitlines()
        metadata_as_a_comment = "\n".join(f"# {l}" for l in metadata_json).encode("ascii")
        header = b"%b\n%b\n%b" % (BEGIN_LOCKFILE_HEADER, metadata_as_a_comment, END_LOCKFILE_HEADER)

        regenerate_command_bytes = (
            f"# This lockfile was autogenerated by Pants. To regenerate, run:\n#\n"
            f"#    {regenerate_command}"
        ).encode("utf-8")

        return b"%b\n#\n%b\n\n%b" % (regenerate_command_bytes, header, lockfile)

    def is_valid_for(
        self,
        expected_invalidation_digest: str | None,
        user_interpreter_constraints: InterpreterConstraints,
        interpreter_universe: Iterable[str],
    ) -> LockfileMetadataValidation:
        """Returns Truthy if this `LockfileMetadata` can be used in the current execution
        context."""
        failure_reasons: set[InvalidLockfileReason] = set()

        if expected_invalidation_digest is None:
            return LockfileMetadataValidation(failure_reasons)

        if self.requirements_invalidation_digest != expected_invalidation_digest:
            failure_reasons.add(InvalidLockfileReason.INVALIDATION_DIGEST_MISMATCH)

        if not self.valid_for_interpreter_constraints.contains(
            user_interpreter_constraints, interpreter_universe
        ):
            failure_reasons.add(InvalidLockfileReason.INTERPRETER_CONSTRAINTS_MISMATCH)

        return LockfileMetadataValidation(failure_reasons)


def calculate_invalidation_digest(requirements: Iterable[str]) -> str:
    """Returns an invalidation digest for the given requirements."""
    m = hashlib.sha256()
    inputs = {
        # `FrozenOrderedSet` deduplicates while keeping ordering, which speeds up the sorting if
        # the input was already sorted.
        "requirements": sorted(FrozenOrderedSet(requirements)),
    }
    m.update(json.dumps(inputs).encode("utf-8"))
    return m.hexdigest()


class InvalidLockfileReason(Enum):
    INVALIDATION_DIGEST_MISMATCH = "invalidation_digest_mismatch"
    INTERPRETER_CONSTRAINTS_MISMATCH = "interpreter_constraints_mismatch"


class LockfileMetadataValidation:
    """Boolean-like value which additionally carries reasons why a validation failed."""

    failure_reasons: set[InvalidLockfileReason]

    def __init__(self, failure_reasons: Iterable[InvalidLockfileReason] = ()):
        self.failure_reasons = set(failure_reasons)

    def __bool__(self):
        return not self.failure_reasons
