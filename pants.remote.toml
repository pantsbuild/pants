# For goals that you'd like to remote, first install the Google cloud CLI and then log in to an
# an account authorized to run the Pants project (you may need to ask a Pants committer for
# to authorize your account). Then, point to this config file and provide the oauth token like this:
#
#  $ ./pants --pants-config-files=pants.remote.toml
#     --remote-oauth-bearer-token-path=<(gcloud auth application-default print-access-token)
#     test tests/python/pants_test/util:strutil
#
# Remoting does not work for every goal, so you should not permanently point to this TOML file, e.g.
# via an env var; only point to it when you want to remote a specific invocation.

[GLOBAL]
remote_execution = true
remote_execution_server = "remotebuildexecution.googleapis.com"
remote_store_server = "remotebuildexecution.googleapis.com"
# This file might not exist on your machine. If this default fails, run `find /usr -name '*.pem'`
# and override this value via the env var PANTS_REMOTE_CA_CERTS_PATH.
remote_ca_certs_path = "/usr/local/etc/openssl/cert.pem"
remote_instance_name = "projects/pants-remoting-beta/instances/default_instance"
remote_execution_extra_platform_properties = [
  # This allows network requests, e.g. to resolve dependencies with Pex.
  "dockerNetwork=standard",
  "container-image=docker://gcr.io/pants-remoting-beta/pants-remote-execution@sha256:9aed33779fabc4dbd3c4a883257f6e3ec96ccc8d530e88abf5bffd7efe8aa8f6",
]

# This should correspond to the number of workers running in Google RBE. See
# https://console.cloud.google.com/apis/api/remotebuildexecution.googleapis.com/quotas?project=pants-remoting-beta&folder&organizationId&duration=PT6H.
process_execution_remote_parallelism = 32
process_execution_speculation_strategy = "local_first"
process_execution_speculation_delay = 10

[pex]
# TODO(#7735): This config is not ideal, that we must specify the PATH for both local and remote
# platforms. This should be replaced by a proper mechanism to differentiate between the two.
executable_search_paths = [
  # These are the interpreter paths we set up on the remote container. We need to specify these
  # because many of our tests for the Python backend need to discover Python interpreters.
  "/pyenv-docker-build/versions/3.8.5/bin:/pyenv-docker-build/versions/3.7.8/bin:/pyenv-docker-build/versions/3.6.11/bin:/pyenv-docker-build/versions/2.7.18/bin",
  # The remote container has binaries like `ld` and `gcc` in /usr/bin.
  "/usr/bin",
  # We include the host PATH so that speculation still works.
  '<PATH>',
]

[python-setup]
# TODO(#7735): This config is not ideal, that we must specify the PATH for both local and remote
# platforms. This should be replaced by a proper mechanism to differentiate between the two.
interpreter_search_paths = [
  # These are the interpreter paths we set up on the remote container.
  "/pyenv-docker-build/versions/3.8.5/bin:/pyenv-docker-build/versions/3.7.8/bin:/pyenv-docker-build/versions/3.6.11/bin:/pyenv-docker-build/versions/2.7.18/bin",
  # We include the host PATH and PEXRC values so that speculation still works.
  # NOTE: These come after the remote paths. Putting them before the remote paths means generic
  # bin dirs like /usr/bin will be on the PATH ahead of the pyenv dirs we actually want to use
  # on the remote side.  The /pyenv-docker-build/ paths are unlikely to exist on local systems,
  # and so will not interfere with interpreter discovery there. This emphasizes
  # that we should fix #7735, and not commingle the paths of two unrelated systems.
  '<PATH>',
  '<PEXRC>',
]

[python-native-code]
ld_flags = []
cpp_flags = []
